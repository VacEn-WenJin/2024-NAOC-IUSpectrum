{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "# matplotlib.use('TkAgg')\n",
    "# matplotlib.use('qtagg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.pyplot import *\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "from math import *\n",
    "#import pandas as pd\n",
    "\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import curve_fit \n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.table import vstack\n",
    "from astropy.coordinates import SkyCoord, ICRS, Galactic\n",
    "# import astropy.units as u\n",
    "import astropy.units as units\n",
    "import astropy.coordinates as coord\n",
    "#from matplotlib.colors import LogNorm\n",
    "\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# #import matplotlib.ticker as mtick\n",
    "\n",
    "\n",
    "import os\n",
    "#%matplotlib widget\n",
    "import seaborn as sns\n",
    "import os, sys\n",
    "\n",
    "\n",
    "# from astropy.io import ascii\n",
    "# from astropy.coordinates import galactocentric_frame_defaults\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "import random\n",
    "from scipy import integrate\n",
    "\n",
    "\n",
    "gcolor = ['c','blue','g','r','orange', 'green','cyan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppxf as ppxf_package\n",
    "from ppxf.ppxf import ppxf\n",
    "import ppxf.ppxf_util as util\n",
    "import ppxf.sps_util as lib\n",
    "import sys,glob\n",
    "from pathlib import Path\n",
    "\n",
    "from ppxf.ppxf import ppxf, robust_sigma\n",
    "\n",
    "from vorbin.voronoi_2d_binning import voronoi_2d_binning\n",
    "from plotbin.display_bins import display_bins\n",
    "\n",
    "from tqdm import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TB_reindex(TB_now):\n",
    "    TB_now = TB_now.reset_index()\n",
    "    TB_now = TB_now.drop(columns='index')\n",
    "    return TB_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bins(wavs):\n",
    "    \"\"\" Given a series of wavelength points, find the edges and widths\n",
    "    of corresponding wavelength bins. \"\"\"\n",
    "    edges = np.zeros(wavs.shape[0]+1)\n",
    "    widths = np.zeros(wavs.shape[0])\n",
    "    edges[0] = wavs[0] - (wavs[1] - wavs[0])/2\n",
    "    widths[-1] = (wavs[-1] - wavs[-2])\n",
    "    edges[-1] = wavs[-1] + (wavs[-1] - wavs[-2])/2\n",
    "    edges[1:-1] = (wavs[1:] + wavs[:-1])/2\n",
    "    widths[:-1] = edges[1:-1] - edges[:-2]\n",
    "\n",
    "    return edges, widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectres(new_wavs, spec_wavs, spec_fluxes, spec_errs=None, fill=None,\n",
    "             verbose=True):\n",
    "\n",
    "    \"\"\"\n",
    "    Function for resampling spectra (and optionally associated\n",
    "    uncertainties) onto a new wavelength basis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    new_wavs : numpy.ndarray\n",
    "        Array containing the new wavelength sampling desired for the\n",
    "        spectrum or spectra.\n",
    "\n",
    "    spec_wavs : numpy.ndarray\n",
    "        1D array containing the current wavelength sampling of the\n",
    "        spectrum or spectra.\n",
    "\n",
    "    spec_fluxes : numpy.ndarray\n",
    "        Array containing spectral fluxes at the wavelengths specified in\n",
    "        spec_wavs, last dimension must correspond to the shape of\n",
    "        spec_wavs. Extra dimensions before this may be used to include\n",
    "        multiple spectra.\n",
    "\n",
    "    spec_errs : numpy.ndarray (optional)\n",
    "        Array of the same shape as spec_fluxes containing uncertainties\n",
    "        associated with each spectral flux value.\n",
    "\n",
    "    fill : float (optional)\n",
    "        Where new_wavs extends outside the wavelength range in spec_wavs\n",
    "        this value will be used as a filler in new_fluxes and new_errs.\n",
    "\n",
    "    verbose : bool (optional)\n",
    "        Setting verbose to False will suppress the default warning about\n",
    "        new_wavs extending outside spec_wavs and \"fill\" being used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    new_fluxes : numpy.ndarray\n",
    "        Array of resampled flux values, first dimension is the same\n",
    "        length as new_wavs, other dimensions are the same as\n",
    "        spec_fluxes.\n",
    "\n",
    "    new_errs : numpy.ndarray\n",
    "        Array of uncertainties associated with fluxes in new_fluxes.\n",
    "        Only returned if spec_errs was specified.\n",
    "    \"\"\"\n",
    "\n",
    "    # Rename the input variables for clarity within the function.\n",
    "    old_wavs = spec_wavs\n",
    "    old_fluxes = spec_fluxes\n",
    "    old_errs = spec_errs\n",
    "\n",
    "    # Make arrays of edge positions and widths for the old and new bins\n",
    "\n",
    "    old_edges, old_widths = make_bins(old_wavs)\n",
    "    new_edges, new_widths = make_bins(new_wavs)\n",
    "\n",
    "    # Generate output arrays to be populated\n",
    "    new_fluxes = np.zeros(old_fluxes[..., 0].shape + new_wavs.shape)\n",
    "\n",
    "    if old_errs is not None:\n",
    "        if old_errs.shape != old_fluxes.shape:\n",
    "            raise ValueError(\"If specified, spec_errs must be the same shape \"\n",
    "                             \"as spec_fluxes.\")\n",
    "        else:\n",
    "            new_errs = np.copy(new_fluxes)\n",
    "\n",
    "    start = 0\n",
    "    stop = 0\n",
    "\n",
    "    # Calculate new flux and uncertainty values, looping over new bins\n",
    "    for j in range(new_wavs.shape[0]):\n",
    "\n",
    "        # Add filler values if new_wavs extends outside of spec_wavs\n",
    "        if (new_edges[j] < old_edges[0]) or (new_edges[j+1] > old_edges[-1]):\n",
    "            new_fluxes[..., j] = fill\n",
    "\n",
    "            if spec_errs is not None:\n",
    "                new_errs[..., j] = fill\n",
    "\n",
    "            # if (j == 0 or j == new_wavs.shape[0]-1) and verbose:\n",
    "            #     warnings.warn(\n",
    "            #         \"Spectres: new_wavs contains values outside the range \"\n",
    "            #         \"in spec_wavs, new_fluxes and new_errs will be filled \"\n",
    "            #         \"with the value set in the 'fill' keyword argument \"\n",
    "            #         \"(by default 0).\",\n",
    "            #         category=RuntimeWarning,\n",
    "            #     )\n",
    "            continue\n",
    "\n",
    "        # Find first old bin which is partially covered by the new bin\n",
    "        while old_edges[start+1] <= new_edges[j]:\n",
    "            start += 1\n",
    "\n",
    "        # Find last old bin which is partially covered by the new bin\n",
    "        while old_edges[stop+1] < new_edges[j+1]:\n",
    "            stop += 1\n",
    "\n",
    "        # If new bin is fully inside an old bin start and stop are equal\n",
    "        if stop == start:\n",
    "            new_fluxes[..., j] = old_fluxes[..., start]\n",
    "            if old_errs is not None:\n",
    "                new_errs[..., j] = old_errs[..., start]\n",
    "\n",
    "        # Otherwise multiply the first and last old bin widths by P_ij\n",
    "        else:\n",
    "            start_factor = ((old_edges[start+1] - new_edges[j])\n",
    "                            / (old_edges[start+1] - old_edges[start]))\n",
    "\n",
    "            end_factor = ((new_edges[j+1] - old_edges[stop])\n",
    "                          / (old_edges[stop+1] - old_edges[stop]))\n",
    "\n",
    "            old_widths[start] *= start_factor\n",
    "            old_widths[stop] *= end_factor\n",
    "\n",
    "            # Populate new_fluxes spectrum and uncertainty arrays\n",
    "            f_widths = old_widths[start:stop+1]*old_fluxes[..., start:stop+1]\n",
    "            new_fluxes[..., j] = np.sum(f_widths, axis=-1)\n",
    "            new_fluxes[..., j] /= np.sum(old_widths[start:stop+1])\n",
    "\n",
    "            if old_errs is not None:\n",
    "                e_wid = old_widths[start:stop+1]*old_errs[..., start:stop+1]\n",
    "\n",
    "                new_errs[..., j] = np.sqrt(np.sum(e_wid**2, axis=-1))\n",
    "                new_errs[..., j] /= np.sum(old_widths[start:stop+1])\n",
    "\n",
    "            # Put back the old bin widths to their initial values\n",
    "            old_widths[start] /= start_factor\n",
    "            old_widths[stop] /= end_factor\n",
    "\n",
    "    # If errors were supplied return both new_fluxes and new_errs.\n",
    "    if old_errs is not None:\n",
    "        return new_fluxes, new_errs\n",
    "\n",
    "    # Otherwise just return the new_fluxes spectrum array\n",
    "    else:\n",
    "        return new_fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Galaxy information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 299792.458  # spped of light [km/s]\n",
    "\n",
    "galaxy_name = 'VCC_1588'\n",
    "spectrum_filename = 'VCC1588_stack.fits'\n",
    "spectrum_z = 0.0042"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic fitting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_range_temp = [4820, 5220]\n",
    "redshift = spectrum_z           # redshift from\n",
    "objfile = Path('./../Ori_Data/'+spectrum_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# templates\n",
    "\n",
    "sps_name = 'emiles'\n",
    "ppxf_dir = Path(lib.__file__).parent\n",
    "basename = f\"spectra_{sps_name}_9.0.npz\"\n",
    "filename = ppxf_dir / 'sps_models' / basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vel_s = c * spectrum_z\n",
    "vel_s = 0\n",
    "vel_dis_s = 40 # Set the dis v = 40 km/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code from example\n",
    "\n",
    "class read_data_cube:\n",
    "    def __init__(self, filename, lam_range, redshift):\n",
    "        \"\"\"Read data cube, de-redshift, log rebin and compute coordinates of each spaxel.\"\"\"\n",
    "\n",
    "        self.read_fits_file(filename)\n",
    "\n",
    "        # Only use the specified rest-frame wavelength range\n",
    "        wave = self.wave/(1 + redshift)      # de-redshift the spectrum\n",
    "        w = (wave > lam_range[0]) & (wave < lam_range[1])\n",
    "        wave = wave[w]\n",
    "        cube = self.cube[w, ...]\n",
    "        cubevar = self.cubevar[w, ...]\n",
    "\n",
    "        signal = np.nanmedian(cube, 0)\n",
    "        noise = np.sqrt(np.nanmedian(cubevar, 0))\n",
    "\n",
    "        # Create coordinates centred on the brightest spaxel\n",
    "        jm = np.argmax(signal)\n",
    "        row, col = map(np.ravel, np.indices(cube.shape[-2:]))\n",
    "        x = (col - col[jm])*self.pixsize_x\n",
    "        y = (row - row[jm])*self.pixsize_y\n",
    "\n",
    "        # Transform cube into 2-dim array of spectra\n",
    "        npix = cube.shape[0]\n",
    "        spectra = cube.reshape(npix, -1)        # create array of spectra [npix, nx*ny]\n",
    "        variance = cubevar.reshape(npix, -1)    # create array of variance [npix, nx*ny]\n",
    "\n",
    "        c = 299792.458  # speed of light in km/s\n",
    "        velscale = np.min(c*np.diff(np.log(wave)))  # Preserve smallest velocity step\n",
    "        lam_range_temp = [np.min(wave), np.max(wave)]\n",
    "        spectra, ln_lam_gal, velscale = util.log_rebin(lam_range_temp, spectra, velscale=velscale)\n",
    "\n",
    "        # Coordinates and spectra only for spaxels with enough signal\n",
    "        self.spectra = spectra\n",
    "        self.variance = variance\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.signal = signal.ravel()\n",
    "        self.noise = noise.ravel()\n",
    "\n",
    "        self.col = col + 1   # start counting from 1\n",
    "        self.row = row + 1\n",
    "        self.velscale = velscale\n",
    "        self.ln_lam_gal = ln_lam_gal\n",
    "        self.fwhm_gal = self.fwhm_gal/(1 + redshift)\n",
    "\n",
    "        self.velfield = np.ndarray(shape=self.cube.shape[1:3])\n",
    "        self.sigfield = np.ndarray(shape=self.cube.shape[1:3])\n",
    "\n",
    "        # self.CD1_1 = self.CD1_1\n",
    "        # self.CD1_2 = self.CD1_2\n",
    "        # self.CD2_1 = self.CD2_1\n",
    "        # self.CD2_2 = self.CD2_2\n",
    "        # self.CRVAL1 = self.CRVAL1\n",
    "        # self.CRVAL2 = self.CRVAL2\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "    def read_fits_file(self, filename):\n",
    "        \"\"\"\n",
    "        Read MUSE cube, noise, wavelength, spectral FWHM and pixel size.\n",
    "\n",
    "        It must return the cube and cuberr as (npix, nx, ny) and wave as (npix,)\n",
    "\n",
    "        IMPORTANT: This is not a general function! Its details depend on the\n",
    "        way the data were stored in the FITS file and the available keywords in\n",
    "        the FITS header. One may have to adapt the function to properly read\n",
    "        the FITS file under analysis.                \n",
    "        \"\"\"\n",
    "\n",
    "        Cut_LHS = 150\n",
    "        Cut_RHS = 150\n",
    "\n",
    "        hdu = fits.open(filename)\n",
    "        head = hdu[0].header\n",
    "        cube = hdu[0].data[Cut_LHS:-Cut_RHS,:,:] * (10 ** 18)\n",
    "        # cube = hdu[0].data[Cut_LHS:-Cut_RHS,:,:]\n",
    "        # cube = hdu[0].data * (10 ** 18)\n",
    "        cubevar = np.empty_like(cube)  # This file contains no errors\n",
    "\n",
    "        # Only use the specified rest-frame wavelength range\n",
    "        wave = head['CRVAL3'] + head['CD3_3']*np.arange(cube.shape[0]) + head['CD3_3']*Cut_LHS\n",
    "\n",
    "        self.cube = cube\n",
    "        self.cubevar = cubevar\n",
    "        self.wave = wave\n",
    "        \n",
    "        # self.fwhm_gal = 2.62  # Median FWHM = 2.62Ã…. Range: 2.51--2.88 (ESO instrument manual). \n",
    "        self.fwhm_gal = 1\n",
    "        # self.pixsize = abs(head[\"CDELT1\"])*3600    # 0.2\"\n",
    "        self.pixsize_x = abs(np.sqrt((head['CD1_1'])**2+(head['CD2_1'])**2))*3600\n",
    "        self.pixsize_y = abs(np.sqrt((head['CD1_2'])**2+(head['CD2_2'])**2))*3600\n",
    "\n",
    "        self.CD1_1 = head['CD1_1']\n",
    "        self.CD1_2 = head['CD1_2']\n",
    "        self.CD2_1 = head['CD2_1']\n",
    "        self.CD2_2 = head['CD2_2']\n",
    "        self.CRVAL1 = head['CRVAL1']\n",
    "        self.CRVAL2 = head['CRVAL2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Galaxy_info = read_data_cube(objfile, lam_range_temp, redshift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devide Radius bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters pre-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWHM_gal = None   # set this to None to skip templates broadening\n",
    "sps = lib.sps_lib(filename, Galaxy_info.velscale, FWHM_gal, norm_range=[4820, 5220])\n",
    "# sps = lib.sps_lib(filename, Galaxy_info.velscale, FWHM_gal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npix, *reg_dim = sps.templates.shape\n",
    "sps.templates = sps.templates.reshape(npix, -1)\n",
    "sps.templates /= np.median(sps.templates) # Normalizes stellar templates by a scalar\n",
    "regul_err = 0.01 # Desired regularization error\n",
    "\n",
    "lam_range_temp = np.exp(sps.ln_lam_temp[[0, -1]])\n",
    "mask0 = util.determine_mask(Galaxy_info.ln_lam_gal, lam_range_temp, width=1000)\n",
    "# nbins = np.unique(bin_num).size\n",
    "# velbin, sigbin, lg_age_bin, metalbin, nspax = np.zeros((5, nbins))\n",
    "# optimal_templates = np.empty((npix, nbins))\n",
    "lam_gal = np.exp(Galaxy_info.ln_lam_gal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ast_Base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
